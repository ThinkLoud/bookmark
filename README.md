# bookmark


## Articles

- [Feature-wise transformations / Distill](https://distill.pub/2018/feature-wise-transformations/) A simple and surprisingly effective family of conditioning mechanisms.
- [NLP's ImageNet moment has arrived](https://thegradient.pub/nlp-imagenet/) by Sebastian Ruder.
- [The Natural Language Decathlon / Salesforce, Richard Socher](https://einstein.ai/research/the-natural-language-decathlon) This challenge spans ten tasks: question answering, machine translation, summarization, natural language inference, sentiment analysis, semantic role labeling, relation extraction, goal-oriented dialogue, database query generation, and pronoun resolution. The goal of the Decathlon is to explore models that generalize to all ten tasks and investigate how such models differ from those trained for single tasks. 

## Papers

## Open sources

- [Glow: Better Reversible Generative Models / OpenAI](https://blog.openai.com/glow/)
- [Horovod/Uber](https://github.com/uber/horovod) Horovod is a distributed training framework for TensorFlow, Keras, and PyTorch. The goal of Horovod is to make distributed Deep Learning fast and easy to use.

## Open Data


## Open courses

- (Udacity)[Self-Driving Fundamentals: Featuring Apollo](https://www.udacity.com/course/self-driving-car-fundamentals-featuring-apollo--ud0419)

## Biomedical

- [What are radiological deep learning models actually learning?](https://medium.com/@jrzech/what-are-radiological-deep-learning-models-actually-learning-f97a546c5b98) by John Zech
   - (Arxiv) [Confounding variables can degrade generalization performance of radiological deep learning models](https://arxiv.org/pdf/1807.00431.pdf)  The performance of CNNs in diagnosing diseases on x-rays may reflect not only their ability to identify disease-specific imaging findings on x-rays, but also their ability to exploit confounding information.
